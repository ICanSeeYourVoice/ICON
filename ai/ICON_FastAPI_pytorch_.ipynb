{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYn8Rwn0mC2b"
   },
   "source": [
    "## 필요한 라이브러리 설치 및 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8XmqbV98R3Ll"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kms\\anaconda3\\envs\\cuda\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import io\n",
    "import numpy as np\n",
    "import uvicorn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pydub import AudioSegment\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from threading import Thread\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pathlib\n",
    "from torchvision import transforms, models\n",
    "from pyngrok import ngrok\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3O0wIJr4T_vM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTugs74wmNbB"
   },
   "source": [
    "## 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWiWqChtmOlk",
    "outputId": "d05689c3-370c-412d-b0c3-225975f2a7ec"
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class CryingResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CryingResNet, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=False)\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.base_model.fc.in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# 모델 및 인코더 로드\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_path = 'analyzeCrying.pth'\n",
    "model = CryingResNet(num_classes=4).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.array(['discomfort', 'hungry', 'pain', 'tired'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrrJJWoDmVQ-"
   },
   "source": [
    "## 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o3E3c2zbUBF8"
   },
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def audio_to_melspectrogram(signal, sr, n_mels=128, fmax=8000, hop_length=256):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=n_mels, fmax=fmax, hop_length=hop_length)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "def split_audio_into_windows(signal, sr, window_size=1.0, hop_size=0.5):\n",
    "    window_samples = int(window_size * sr)\n",
    "    hop_samples = int(hop_size * sr)\n",
    "    windows = []\n",
    "    for start in range(0, len(signal) - window_samples + 1, hop_samples):\n",
    "        end = start + window_samples\n",
    "        windows.append(signal[start:end])\n",
    "    return windows\n",
    "\n",
    "def is_crying_window(window, sr, threshold=0.01):\n",
    "    rms = librosa.feature.rms(y=window)[0]\n",
    "    return np.max(rms) > threshold\n",
    "\n",
    "def preprocess_audio_with_windows(file_content, sample_rate=16000, window_size=1.0, hop_size=0.5, img_width=431):\n",
    "    signal, sr = librosa.load(io.BytesIO(file_content), sr=sample_rate)\n",
    "    if len(signal) == 0:\n",
    "        return None\n",
    "\n",
    "    windows = split_audio_into_windows(signal, sr, window_size, hop_size)\n",
    "    selected_windows = [window for window in windows if is_crying_window(window, sr)]\n",
    "\n",
    "    if len(selected_windows) == 0:\n",
    "        return None\n",
    "\n",
    "    # 울음소리 시작 윈도우 찾기\n",
    "    start_index = next((i for i, window in enumerate(windows) if is_crying_window(window, sr)), None)\n",
    "    if start_index is None:\n",
    "        return None\n",
    "\n",
    "    # 선택된 첫 번째 윈도우를 Mel-spectrogram으로 변환\n",
    "    mel_spec = audio_to_melspectrogram(windows[start_index], sr)\n",
    "    if mel_spec.shape[1] > img_width:\n",
    "        mel_spec = mel_spec[:, :img_width]\n",
    "    else:\n",
    "        mel_spec = np.pad(mel_spec, ((0, 0), (0, img_width - mel_spec.shape[1])), 'constant')\n",
    "\n",
    "    mel_spec = torch.tensor(mel_spec, dtype=torch.float32).unsqueeze(0).repeat(3, 1, 1)\n",
    "    mel_spec = transforms.Normalize((0.5,), (0.5,))(mel_spec)\n",
    "    mel_spec = mel_spec.unsqueeze(0)  # Add batch dimension\n",
    "    return mel_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pp9VsJYlnDGC"
   },
   "source": [
    "# FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5hkaaWrsl_2i"
   },
   "outputs": [],
   "source": [
    "@app.post(\"/api/v1/predict\")\n",
    "async def predict(data: UploadFile = File(...)):\n",
    "    file_contents = await data.read()\n",
    "    mel_spec = preprocess_audio_with_windows(file_contents)\n",
    "\n",
    "    if mel_spec is None:\n",
    "        return {\"prediction\": \"hungry\"}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mel_spec = mel_spec.to(device)  # GPU로 이동\n",
    "        output = model(mel_spec)\n",
    "        pred_label = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    predicted_class = label_encoder.inverse_transform([pred_label])[0]\n",
    "    return {\"prediction\": predicted_class}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8m7Frd2enUmV"
   },
   "source": [
    "# 로컬서버 실행 및 Ngrok 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCSkP3yxnUJZ",
    "outputId": "045a89b0-aa4f-400d-9a22-60b503340baa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [25828]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<NgrokTunnel: \"https://i-con-analyze.ngrok.io\" -> \"http://localhost:8000\">"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"debug\")\n",
    "\n",
    "# 서버를 백그라운드에서 실행\n",
    "thread = Thread(target=run)\n",
    "thread.start()\n",
    "\n",
    "# ngrok을 통해 포트 8000에 연결\n",
    "ngrok.set_auth_token(\"2fnaK9lUVPQLxAIc1IqqHDZWy69_5AMZQM2HYGvbAwG4wKFem\")\n",
    "ngrok.connect(8000, hostname=\"i-con-analyze.ngrok.io\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
